# Comment rendre un SLM plus malin

Dans ce tutoriel, nous allons voir comment rendre un SLM plus malin en utilisant des donnÃ©es de contexte.

> J'utiliserais mon projet [Parakeet](https://github.com/parakeet-nest/parakeet) pour illustrer ce tutoriel. Mais vous pouvez facilement adapter les concepts avec d'autres frameworks comme LangChain.

## SLM ?

Je vous donne ma dÃ©finition de SLM ou Small Language Model> C'est donc un LLM, qui est "petit" (voire mÃªme trÃ¨s petit) par rapport Ã  un modÃ¨le de langage complet, qui est capable de gÃ©nÃ©rer du texte. En voici quelques uns :

- Tinyllama (637 MB)
- Tinydolphin (636 MB)
- Gemma:2b (1.7 GB) et Gemma2:2b (1.6 GB)
- Phi3:mini (2.2 GB) et Phi3.5 (2.2 GB)
- Qwen:0.5b (394 MB), Qwen2:0.5b (352 MB) et Qwen2:1.5b (934 MB)
- ...

Ma prÃ©fÃ©rence va Ã  des modÃ¨les capable de s'exÃ©cuter confortablement sur un **Raspberry Pi 5** avec 8Go de RAM, donc sans GPU. J'aurais tendance Ã  dire que les modÃ¨les de moins de 1Go sont les plus adaptÃ©s (et ont ma prÃ©fÃ©rence).

Je maintiens une liste de modÃ¨les que j'ai testÃ© et qui fonctionnent bien sur un Raspberry Pi 5 avec 8Go de RAM. Vous pouvez la consulter ici : [Awesome SLMs](https://github.com/parakeet-nest/awesome-slms).

> J'utilise le projet [Ollama]() pour charger et exÃ©cuter les modÃ¨les.

## Mon objectif

Aujjourd'hui, mon objectif est de tenter de transformer le modÃ¨le **`Qwen:0.5b`** en un spÃ©cialiste des fougÃ¨res. Pour cela, je vais lui fournir des donnÃ©es de contexte sur les fougÃ¨res, et je vais lui poser diverses questions.

## PrÃ©requis:

### VÃ©rifier que le modÃ¨le ou les modÃ¨les que je vais utiliser n'y connaissent rien en fougÃ¨res

Pour vÃ©rifier que le modÃ¨le **`Qwen2:0.5b`** ne sait rien sur les fougÃ¨res, je vais lui poser une question sur les fougÃ¨res. Pour cela, j'utilise le script suivant:

```bash
curl http://localhost:11434/api/chat \
-H "Content-Type: application/json" \
-d '
{
  "model": "qwen2:0.5b",
  "messages": [
    {
      "role": "system",
      "content": "You are an expert in botanics and ferns."
    },
    {
      "role": "user",
      "content": "Give me a list of ferns of the Dryopteridaceae variety"
    }
  ],
  "stream": false
}' | jq '.message.content'
```

âœ‹ **Tout au long de mes expÃ©rimentation** j'ai fait des tests avec plusieurs modÃ¨les pour voir lequel est le plus adaptÃ© Ã  mes exigences. Notamment celle de pouvoir fonctionner confortablement sur un Pi 5. Mon choix dÃ©finitif s'est portÃ© sur le modÃ¨le **`Qwen2:0.5b`**. Donc je ne vous prÃ©senterai que les rÃ©sultats obtenus avec ce modÃ¨le. Mais rien ne vous empÃªche de tester avec d'autres modÃ¨les. Je vous encourage mÃªme Ã  le faire. Je proposerais aussi quelaues hypothÃ¨ses et conclusions pour expliquer les choix et les rÃ©sultats obtenus. Cela devrat ensuite vous permettre de faire vos propres expÃ©rimentations et les adapter Ã  vos besoins.

### La prÃ©paration des donnÃ©es

Pour commencer, je dois gÃ©nÃ©rer un fichier de donnÃ©es sur les fougÃ¨res qui serq mon unique source de vÃ©ritÃ©. Pour cela, j'ai crÃ©Ã© un fichier `ferns.json` en demandant de l'aide Ã  **ChatGPT4o**. Pour cela j'ai utilisÃ© le prompt suivant:

```
You are an expert in botanics and your main topic is about the ferns.

I want a list of 10 varieties of ferns with their characteristics and 5 ferns per variety.

the output format is in JSON:
```json
[
    {
        "variety": "name of the variety of ferns",
        "description": "Descriptionof the variety of ferns",
        "ferns": [
            {
                "name": "scientifict name of the fern",
                "common_ame": "common name of the fern",
                "description": "description and characteristics of the fern"
            },
        ]
    },
]
```

Voici un extrait de ce fichier:

```json
[
    {
        "variety": "Polypodiaceae",
        "description": "A family of ferns known for their leathery fronds and widespread distribution in tropical and subtropical regions.",
        "ferns": [
            {
                "name": "Polypodium vulgare",
                "common_name": "Common Polypody",
                "description": "A hardy fern with leathery, evergreen fronds that thrive in rocky and shaded areas."
            },
            {
                "name": "Polypodium glycyrrhiza",
                "common_name": "Licorice Fern",
                "description": "Known for its sweet-tasting roots, this fern grows on moist, shaded rocks and tree trunks."
            },
```

ğŸ“ vous pouvez trouver le fichier complet ici: [ferns.json](https://github.com/parakeet-nest/parakeet/tree/main/examples/42-make-a-slm-smarter/data/ferns.json)

### Mise en forme des donnÃ©es

Ensuite, j'ai transformÃ© le fichier JSON en deux fichiers markdown avec les mÃªme donnÃ©es mais avec des structures diffÃ©rentes. Voici les structures de ces fichiers:

#### `ferns.1.md`

```markdown
# Title of the report

## Variety: name of the variety of ferns
*Description:*
Description of the variety of ferns

### Ferns:
- **name:** **scientific name of the fern**
  **common name:** common name of the fern
  **description:** description and characteristics of the fern
```

#### `ferns.2.md`

```markdown
# Title of the report

## Variety: name of the variety of ferns
*Description:*
Description of the variety of ferns

### Ferns:

#### Name of the fern

**name:** **scientific name of the fern**
**common name:** common name of the fern
**description:** description and characteristics of the fern
```

> Le second fichier est un peu plus structurÃ© que le premier grÃ¢ce aux titres de paragraphes. Cela me permettra de tester si la structure des donnÃ©es a un impact sur les rÃ©sultats obtenus.

ğŸ“ Vous pouvez trouver les fichiers complets ici: [ferns.1.md](https://github.com/parakeet-nest/parakeet/tree/main/examples/42-make-a-slm-smarter/data/ferns.1.md) et [ferns.2.md](https://github.com/parakeet-nest/parakeet/tree/main/examples/42-make-a-slm-smarter/data/ferns.2.md)

## 1Ã¨res expÃ©rimentations

J'ai dÃ©cidÃ© d'aller au plus simple est de crÃ©er un prompt qui sera composÃ© des Ã©lÃ©ments suivants:

- Les instructions pour le modÃ¨le.
- Le contenu**complet** du fichier`ferns.1.md` ou`ferns.2.md`, ce que j'appelle le**contexte**.
- La question que je vais poser au modÃ¨le.

En Go avec **Parakeet**, cela donne quelque chose comme Ã§a:

```golang
Messages: []llm.Message{
    {Role: "system", Content: systemContent},
    {Role: "system", Content: contextContext},
    {Role: "user", Content: question},
},
```

Et les instructions pour le modÃ¨le:

```golang
systemContent := `**Instruction:**
You are an expert in botanics.
Please use only the content provided below to answer the question.
Do not add any external knowledge or assumptions.`
```

ğŸ“ Vous pouvez trouver le code complet ici: [01-context](https://github.com/parakeet-nest/parakeet/tree/main/examples/42-make-a-slm-smarter/01-context)

### Questions

Pour faire mes tests, j'ai utilisÃ© les questions suivantes:

- **Question 1:** Give me a list of ferns of the Dryopteridaceae variety
- **Question 2:** What is the common name Dryopteris cristata?

Pour cette premiÃ¨re sÃ©rie de tests, j'ai utilisÃ© trois modÃ¨les **`Qwen:0.5b`**, **`Qwen2:0.5b`** et **`CognitiveComputations/dolphin-gemma2`** (1.6 GB).

Les rÃ©sultats obtenus sont les suivants:

#### Avec `ferns.1.md`

| LLM + ferns.1.md | Question 1 | Question 2 |
| ---------------- | ---------- | ---------- |
| qwen:0.5b        | ğŸ˜¡         | ğŸ˜¡         |
| qwen2:0.5b       | ğŸ˜¡         | ğŸ˜¡         |
| dolphin-gemma2   | ğŸ™‚         | ğŸ™‚         |

> - ğŸ˜¡: rÃ©sultat faux ou incomplet
> - ğŸ™‚: rÃ©sultat satisfaisant

#### Avec `ferns.2.md`

| LLM + ferns.2.md | Question 1 | Question 2 |
| ---------------- | ---------- | ---------- |
| qwen:0.5b        | ğŸ˜¡         | ğŸ˜¡         |
| qwen2:0.5b       | ğŸ˜¡         | ğŸ˜¡         |
| dolphin-gemma2   | ğŸ˜¡         | ğŸ™‚         |

> - ğŸ˜¡: rÃ©sultat faux ou incomplet
> - ğŸ™‚: rÃ©sultat satisfaisant

### HypothÃ¨ses et Observations

- **dolphin-gemma2** a dÃ©jÃ  des connaissances sur les fougÃ¨res, donc il a pu rÃ©pondre correctement Ã  la question en s'appuyant sur ses connaissances et les informations fournis (mÃªme si thÃ©oriquement les instructions Ã©taient de n'utiliser que le contexte fourni).
- **dolphin-gemma2** semble Ãªtre capable de s'en sortir avec un contexte de grande taille.
- *qwen:0.5b** et**qwen2:0.5b** n'ont pas pu rÃ©pondre correctement aux questiona. Cela peut Ãªtre dÃ» Ã  sa capacitÃ© Ã  traiter des contextes plus grands.
- La structure des donnÃ©es semble avoir un impact sur les rÃ©sultats obtenus avec**dolphin-gemma2** - mais pourtant j'aurais pensÃ© que la seconde structure de document serait plus facilement exploitable. Nous verrons si cela se confirme par la suite.

Ma premiÃ¨re hypothÃ¨se ou constatation serait que **qwen:0.5b** et **qwen2:0.5b** (donc des trÃ©s petits LLMs) ne sont pas capable d'exploiter un trÃ¨s grand contexte, mÃªme si il est structurÃ©e.

Il faut donc aider **qwen:0.5b** et **qwen2:0.5b** Ã  "se concentrer" sur des donnÃ©es prÃ©cises et "plus proches" des questions. J'ai donc reproduit les mÃªmes expÃ©rimentations mais en rÃ©duisant la taille du contexte.

## 2Ã¨me sÃ©rie d'expÃ©rimentations: rÃ©duire la taille du contexte

Pour cette seconde sÃ©rie d'expÃ©rimentations, j'ai rÃ©duit la taille du contexte en ne gardant que les informations sur une seule variÃ©tÃ© de fougÃ¨res. J'ai donc crÃ©Ã© un fichier `ferns.1.extract.md` et `ferns.2.extract.md` qui contiennent les informations sur la variÃ©tÃ© **Dryopteridaceae**.

ğŸ“ J'utilise le mÃªme code pour exÃ©cuter les exemples : [01-context](https://github.com/parakeet-nest/parakeet/tree/main/examples/42-make-a-slm-smarter/01-context)

**Pour `ferns.1.extract.md`**:

```markdown
# Fern Varieties Report

## Variety: Dryopteridaceae
*Description:*
A large family of ferns with robust and often leathery fronds, commonly found in woodlands.

### Ferns:
- **name:** **Dryopteris filix-mas**
  **common name:** Male Fern
  **description:** A sturdy fern with pinnate fronds, commonly found in temperate forests.

- **name:** **Dryopteris marginalis**
  **common name:** Marginal Wood Fern
  **description:** Known for its evergreen fronds, this fern thrives in rocky, shaded environments.

- **name:** **Dryopteris erythrosora**
  **common name:** Autumn Fern
  **description:** This fern features striking copper-red fronds that mature to green.

- **name:** **Dryopteris cristata**
  **common name:** Crested Wood Fern
  **description:** A fern with uniquely crested fronds, typically found in wetland areas.

- **name:** **Dryopteris affinis**
  **common name:** Golden Male Fern
  **description:** A robust fern with yellowish fronds and a preference for moist, shaded habitats.
```

**Pour `ferns.2.extract.md`**:

```markdown
# Fern Varieties Report

## Variety: Dryopteridaceae
*Description:*
A large family of ferns with robust and often leathery fronds, commonly found in woodlands.

### Ferns:

#### Dryopteris filix-mas

**name:** **Dryopteris filix-mas**  
**common name:** Male Fern  
**description:** A sturdy fern with pinnate fronds, commonly found in temperate forests.

#### Dryopteris marginalis

**name:** **Dryopteris marginalis**  
**common name:** Marginal Wood Fern  
**description:** Known for its evergreen fronds, this fern thrives in rocky, shaded environments.

#### Dryopteris erythrosora

**name:** **Dryopteris erythrosora**  
**common name:** Autumn Fern  
**description:** This fern features striking copper-red fronds that mature to green.

#### Dryopteris cristata

**name:** **Dryopteris cristata**  
**common name:** Crested Wood Fern  
**description:** A fern with uniquely crested fronds, typically found in wetland areas.

#### Dryopteris affinis

**name:** **Dryopteris affinis**  
**common name:** Golden Male Fern  
**description:** A robust fern with yellowish fronds and a preference for moist, shaded habitats.
```

ğŸ“ Vous pouvez trouver les fichiers complets ici: [ferns.1.extract.md](https://github.com/parakeet-nest/parakeet/tree/main/examples/42-make-a-slm-smarter/data/ferns.1.extract.md) et [ferns.2.extract.md](https://github.com/parakeet-nest/parakeet/tree/main/examples/42-make-a-slm-smarter/data/ferns.2.extract.md)

J'ai ensuite rÃ©pÃ©tÃ© les mÃªmes expÃ©rimentations que prÃ©cÃ©demment (Questions identiques).

### RÃ©sultats

| LLM + ferns.1.extract.md | Question 1 | Question 2 |
| ------------------------ | ---------- | ---------- |
| qwen:0.5b                | ğŸ˜¡         | ğŸ˜¡         |
| qwen2:0.5b               | ğŸ™‚         | ğŸ™‚         |
| dolphin-gemma2           | ğŸ™‚         | ğŸ˜¡         |

| LLM + ferns.2.extract.md | Question 1 | Question 2 |
| ------------------------ | ---------- | ---------- |
| qwen:0.5b                | ğŸ™‚         | ğŸ˜¡         |
| qwen2:0.5b               | ğŸ™‚         | ğŸ™‚         |
| dolphin-gemma2           | ğŸ™‚         | ğŸ™‚         |

Clairement, le fait de rÃ©duire la taille du contexte a permis Ã  **qwen2:0.5b** de mieux exploiter les informations et de rÃ©pondre correctement aux questions. **dolphin-gemma2** a eu des rÃ©sultats mitigÃ©s, mais il a quand mÃªme Ã©tÃ© capable de rÃ©pondre correctement Ã  certaines questions.

De plus, la structure des donnÃ©es semble avoir un impact sur les rÃ©sultats obtenus avec les trois modÃ¨les. La seconde structure de document semble Ãªtre plus facilement exploitable.

### Conclusion

âœ‹ **Je rÃ©alise que mes hypothÃ¨ses et conclusions sont basÃ©es sur un nombre limitÃ© de tests. Il serait intÃ©ressant de rÃ©pÃ©ter ces expÃ©rimentations avec un plus grand nombre de modÃ¨les et de questions.**

NÃ©anmoins, pour la suite de mes expÃ©rimentations, je vais continuer Ã  utiliser **qwen2:0.5b** et la seconde structure de document.

Bien sÃ»r, je voudrais pouvoir interroger mon expert en fougeres sur d'autres variÃ©tÃ©s de fougÃ¨res. Pour cela, je vais devoir mettre en place un systÃ¨me qui sera capable d'extraire uniquement les informations pertinentes pour une question donnÃ©e. Nous allons donc passer Ã  la phase suivante de nos expÃ©rimentations et faire du **RAG** (
Retrieval-augmented generation) pour extraire les informations pertinentes.

## 3Ã¨me sÃ©rie d'expÃ©rimentations: recherche de similaritÃ© pour fournir un contexte plus pertinent mais plus petit

ğŸ“ Cette fois-ci le code pour exÃ©cuter les exemples est ici : [02-rag](https://github.com/parakeet-nest/parakeet/tree/main/examples/42-make-a-slm-smarter/02-rag)

Ce programme va faire plusieurs choses:

- Il va charger le document`ferns.2.split.md`
- Le splitter en plusieurs parties (une par variÃ©tÃ© de fougÃ¨res)
- Calculer les vecteurs (embeddings) de chaque partie (ou chunk) avec l'aide d'un LLM appropriÃ© pour faire de la gÃ©nÃ©ration d'embeddings. Je ferais des essais avec**all-minilm:33m**,**nomic-embed-text** et**mxbai-embed-large**.
- Attendre une question utilisateur
- Calculer le vecteur de la question
- Calculer la ou les similaritÃ©es entre le vecteur de la question et les vecteurs des parties du document.
- CrÃ©er un contexte avec la ou les parties du document qui ont la plus grande similaritÃ© avec la question.
- Poser la question au modÃ¨le**qwen2:0.5b**  avec le contexte gÃ©nÃ©rÃ©.

> Je ferqis aussi des essais avec**qwen2:1.5b**.

âœ‹ `ferns.2.split.md` est un fichier markdown qui contient les mÃªmes informations que `ferns.2.md` (Il est aussi structurÃ© de la mÃªme maniÃ¨re), mais dans lequels j'ai ajoutÃ© un **marqueur** `<!-- SPLIT -->` Ã  chaque fin de section d'une variÃ©tÃ© de fougÃ¨re, pour indiquer les diffÃ©rentes parties du document. Cela me permettra de dÃ©couper le document en plusieurs parties et de calculer les embeddings de chaque partie.

ğŸ“ Vous pouvez trouver le fichier complet ici: [ferns.2.split.md](https://github.com/parakeet-nest/parakeet/tree/main/examples/42-make-a-slm-smarter/data/ferns.2.split.md)

âœ‹ Pour cette expÃ©rimentation, j'ai utilisÃ© un "in memory vectore store" pour stocker les vecteurs des parties du document, et la distance "cossine" pour calculer la similaritÃ© entre les vecteurs des parties du document et le vecteur de la question. Ces fonctionnalitÃ©s sont disponibles dans le projet [Parakeet](https://github.com/parakeet-nest/parakeet).

> Parakeet fournit d'autres fonctionnalitÃ©s pour faire du RAG, notament avec **Elasticsearch**. Vous pouvez consulter la documentation et les exemples pour plus d'informations.

### Recherche de similaritÃ©s

Pour faire les recherche de similaritÃ©s, j'ai utilisÃ© la fonction `SearchTopNSimilarities` de [Parakeet](https://github.com/parakeet-nest/parakeet). Voici la signature de cette fonction:

```golang
func (mvs *embeddings.MemoryVectorStore) SearchTopNSimilarities(embeddingFromQuestion llm.VectorRecord, limit float64, max int) ([]llm.VectorRecord, error)
```

```text
SearchTopNSimilarities searches for the top N similar vector records based on the given embedding from a question. It returns a slice of vector records and an error if any. The limit parameter specifies the minimum similarity score for a record to be considered similar. The max parameter specifies the maximum number of vector records to return.
```

Donc,par exemple si j'utilise:

```golang
similarities, err := store.SearchTopNSimilarities(embeddingFromQuestion, 0.5, 1)
```

La fonction va chercher les vecteurs (dans le vector store) qui ont une distance cosine supÃ©rieure ou Ã©gale Ã  0.5 avec le vecteur de la question. Et elle va retourner le vecteur avec le meilleure score.

Et si je veux chercher les 3 meilleurs vecteurs:

```golang
similarities, err := store.SearchTopNSimilarities(embeddingFromQuestion, 0.5, 3)
```

### Questions

Pour faire cette nouvelle expÃ©rimentation, j'ai utilisÃ© les mÃªmes questions que pour l'experimentation prÃ©cÃ©dente:

- **Question 1:** Give me a list of ferns of the Dryopteridaceae variety
- **Question 2:** What is the common name Dryopteris cristata?

### RÃ©sultats

Les rÃ©sultats obtenus sont les suivants:

|   | LLM + ferns.2.split.md | Question 1 | Question 2 | TopNSimilarities |
| - | ---------------------- | ---------- | ---------- | ---------------- |
| 1 | qwen2:0.5b             | ğŸ˜¡         | ğŸ™‚ğŸ˜¡       | 3                |
| 2 | qwen2:0.5b             | ğŸ™‚         | ğŸ™‚ğŸ˜¡       | 1                |

1. **Retourne jusqu'Ã  3 similaritÃ©s**: Dans le 1ers cas**qwen2:0.5b** ne peut pas rÃ©pondre correctement Ã  la question, il boucle. Concernant la question 2, il rÃ©pond correctement si je n'ai qu'une seule similaritÃ©. Mais il ne peut pas rÃ©pondre correctement si j'ai plus d'une similaritÃ©. Et certaines fois, il ne trouve aucune similaritÃ© mÃªme si l'information existe.
2. **Retourne 1 similaritÃ©**: Dans le 2Ã¨me cas,**qwen2:0.5b** rÃ©pond correctement Ã  la question 1 et 2. Mais parfois il ne trouve aucune similaritÃ© mÃªme si l'information existe.

#### 1Ã¨res HypothÃ¨ses et Observations

- Il ne faut remonter qu'une seule similaritÃ© pour que**qwen2:0.5b** puisse rÃ©pondre correctement Ã  la question (pour Ãªtre focus).
- Il ne faut pas remonter 0 similaritÃ© pour que**qwen2:0.5b** puisse rÃ©pondre correctement Ã  la question (pour avoir l'information).
- Je dois donc trouver un moyen d'amÃ©liorer la recherche de similaritÃ© pour Ãªtre sÃ»r de retrouver l'information.

Je vais donc utiliser un autre modÃ¨le pour faire la gÃ©nÃ©ration d'embeddings: ****nomic-embed-text****.

### Utilisation de nomic-embed-text

|   | LLM + ferns.2.split.md | Question 1 | Question 2 | TopNSimilarities |
| - | ---------------------- | ---------- | ---------- | ---------------- |
| 1 | qwen2:0.5b             | ğŸ˜¡         | ğŸ™‚         | 3                |
| 2 | qwen2:0.5b             | ğŸ™‚         | ğŸ˜¡         | 1                |

MÃªme si il y a une amÃ©lioration, je me retrouve encore avec des recherches de similaritÃ© qui ne sont pas satisfaisantes (0 similaritÃ© mÃªme si l'information existe). Je vais donc essayer avec **mxbai-embed-large**.

### Utilisation de mxbai-embed-large

|   | LLM + ferns.2.split.md | Question 1 | Question 2 | TopNSimilarities |
| - | ---------------------- | ---------- | ---------- | ---------------- |
| 1 | qwen2:0.5b             | ğŸ˜¡         | ğŸ™‚         | 3                |
| 2 | qwen2:0.5b             | ğŸ™‚         | ğŸ™‚ğŸ˜¡       | 1                |

Clairement je dois limiter Ã  une seule similaritÃ© pour que **qwen2:0.5b** puisse rÃ©pondre le plus correctement Ã  la question.

L'utilisation de **mxbai-embed-large** a apportÃ© une amÃ©lioration significative. Je n'ai plus de resultat de recherche de similaritÃ© qui ne sont pas satisfaisants (l'information est bien retrouvÃ©e).

Cependant **qwen2:0.5b** ne rÃ©pond pas toujours correctement Ã  la question 2 et utilise l'information d'une autre fougÃ¨re de la mÃªme variÃ©tÃ©.

Je vais donc faire le mÃªme test avec d'autres modÃ©les pour voir si je peux obtenir de meilleurs rÃ©sultats.

## 4Ã¨me sÃ©rie d'expÃ©rimentations: essais avec d'autres modÃ¨les

Je conserve **mxbai-embed-large** pour la gÃ©nÃ©ration d'embeddings et je vais faire des essais avec d'autres modÃ¨les pour la complÃ©tion.

|   | LLM + ferns.2.split.md | Question 1 | Question 2 | TopNSimilarities |
| - | ---------------------- | ---------- | ---------- | ---------------- |
| 1 | qwen2:1.5b             | ğŸ™‚         | ğŸ™‚         | 3                |
| 2 | qwen2:1.5b             | ğŸ™‚         | ğŸ™‚         | 1                |
| 3 | tinydolphin            | ğŸ˜¡         | ğŸ˜¡         | 3                |
| 4 | tinydolphin            | ğŸ˜¡ğŸ™‚       | ğŸ™‚         | 1                |

Les tailles de paramÃ¨tres des modÃ¨les sont les suivantes:

- **qwen2:0.5b** (352 MB)`0.5b`
- **qwen2:1.5b** (934 MB)`1.5b`
- **tinydolphin** (636 MB)`1.1b`

Malheureusement, **qwen2:0.5b** ne me donne pas entiÃ¨rement satisfaction pour mon cas d'usage d'expert en fougÃ¨re.

**qwen2:1.5b** est beaucoup mieux que **qwen2:0.5b**. Il rÃ©pond correctement Ã  la question 1 et 2. Il est capable de rÃ©pondre correctement mÃªme si je remonte 3 similaritÃ©s.

**tinydolphin** est aussi capable de rÃ©pondre correctement Ã  la question 1 et 2. Mais pour la question 1, il arrive qu'il me retourne des rÃ©sultats en doubles. Par contre il est nÃ©cessaire de limiter Ã  un seul rÃ©sultat la recherche de similaritÃ© pour avoir un rÃ©sultat satisfaisant.

Je me demande si je ne pourrais pas aider un peu **tinydolphin** en lui fournissant un contexte plus prÃ©cis et structurÃ© pour lui permettre de rÃ©pondre correctement Ã  la question 1 (obtenir la liste des fougÃ¨res d'une variÃ©tÃ© donnÃ©e).

## 5Ã¨me sÃ©rie d'expÃ©rimentations: essais avec un contexte plus prÃ©cis et structurÃ©

J'ai donc crÃ©Ã© un nouveau fichier `ferns.2.split.list.md` qui contient les informations les mÃªmes informations que `ferns.2.split.md` mais Ã¡ la fin de chaue section de la variÃ©tÃ© de fougÃ¨re, j'ai ajoutÃ© une liste des noms des fougÃ¨res de la variÃ©tÃ©. Comme ceci par exemple:

```markdown
## List of Ferns of the variety: Dryopteridaceae

- **Dryopteris filix-mas** (Male Fern)
- **Dryopteris marginalis** (Marginal Wood Fern)
- **Dryopteris erythrosora** (Autumn Fern)
- **Dryopteris cristata** (Crested Wood Fern)
- **Dryopteris affinis** (Golden Male Fern)
```

En fait, je prÃ©sente la mÃªme information plusieurs fois dans le document. Mais sous une forme diffÃ©rente.

ğŸ“ Vous pouvez trouver le fichier complet ici: [ferns.2.split.list.md](https://github.com/parakeet-nest/parakeet/tree/main/examples/42-make-a-slm-smarter/data/ferns.2.split.list.md)

Je conserve **mxbai-embed-large** pour la gÃ©nÃ©ration d'embeddings et je vais faire les mÃªmes texte que dans l'expÃ©rimentation prÃ©cÃ©dente mais qvec le fichier `ferns.2.split.list.md`.

ğŸ“ Cette fois-ci le code pour exÃ©cuter les exemples est ici : [03-rag-list](https://github.com/parakeet-nest/parakeet/tree/main/examples/42-make-a-slm-smarter/03-rag-list)

### RÃ©sultats

|   | LLM + ferns.2.split.list.md | Question 1 | Question 2 | TopNSimilarities |
| - | --------------------------- | ---------- | ---------- | ---------------- |
| 1 | qwen2:1.5b                  | ğŸ™‚         | ğŸ™‚         | 3                |
| 2 | qwen2:1.5b                  | ğŸ™‚         | ğŸ™‚         | 1                |
| 3 | tinydolphin                 | ğŸ˜¡         | ğŸ˜¡ğŸ™‚       | 3                |
| 4 | tinydolphin                 | ğŸ™‚         | ğŸ™‚         | 1                |

Cette fois ci en ajoutant des informations supplÃ©mentaires dans le contexte, j'ai pu obtenir de meilleurs rÃ©sultats avec **tinydolphin**. Il rÃ©pond correctement Ã  la question 1 et 2 si je conserve une seule similaritÃ©.

## Conclusion

Ce type d'expÃ©rimentation est trÃ¨s intÃ©ressant mais peut durer indÃ©finiment. Il est important de bien dÃ©finir les objectifs et les contraintes de l'expÃ©rimentation pour ne pas s'Ã©garer.

Pour mon cas d'usage, mes conclusions sont les suivantes:

Pour permettre Ã  un SLM d'Ãªtre un expert en fougÃ¨res, il est nÃ©cessaire de lui fournir des donnÃ©es de contexte sur les fougÃ¨res. Il est important de structurer ces donnÃ©es de maniÃ¨re Ã  ce qu'elles soient facilement exploitables par le modÃ¨le. Il est Ã©galement important de limiter la taille du contexte pour permettre au modÃ¨le de traiter les informations de maniÃ¨re efficace.

Et je retiendrais les candidats suivants pour crÃ©er un bon expert en fougÃ¨res:

|   | LLM + ferns.2.split.list.md | ferns.2.list.md | ferns.2.split.list.md | TopNSimilarities |
| - | --------------------------- | --------------- | --------------------- | ---------------- |
| 1 | qwen2:1.5b                  | âœ…              | âœ…                    | 3                |
| 2 | qwen2:1.5b                  | âœ…              | âœ…                    | 1                |
| 4 | tinydolphin                 |                 | âœ…                    | 1                |


Je vous encourage Ã  faire vos propres expÃ©rimentations et Ã  adapter les concepts prÃ©sentÃ©s ici Ã  vos besoins.
